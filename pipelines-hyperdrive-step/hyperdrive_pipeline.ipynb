{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning pipeline examples\n",
    "\n",
    "In this example, we'll build a pipeline for Hyperparameter tuning. This pipeline will test multiple hyperparameter permutations and then register the best model.\n",
    "\n",
    "**Note:** This example requires that you've ran the notebook from the first tutorial, so that the dataset and compute cluster are set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import azureml.core\r\n",
    "from azureml.core import Workspace, Experiment, Dataset, RunConfiguration, Environment\r\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\r\n",
    "from azureml.pipeline.steps import PythonScriptStep, HyperDriveStep, HyperDriveStepRun\r\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\r\n",
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\r\n",
    "from azureml.train.hyperdrive import choice, loguniform, uniform\r\n",
    "from azureml.core import ScriptRunConfig\r\n",
    "\r\n",
    "print(\"Azure ML SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will connect to the workspace. The command `Workspace.from_config()` will either:\n",
    "* Read the local `config.json` with the workspace reference (given it is there) or\n",
    "* Use the `az` CLI to connect to the workspace and use the workspace attached to via `az ml folder attach -g <resource group> -w <workspace name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\r\n",
    "print(f'WS name: {ws.name}\\nRegion: {ws.location}\\nSubscription id: {ws.subscription_id}\\nResource group: {ws.resource_group}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Let's reference the dataset from the first tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Dataset.get_by_name(ws, \"german-credit-train-tutorial\")\n",
    "training_dataset_consumption = DatasetConsumptionConfig(\"training_dataset\", training_dataset).as_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define the parameter sampling (defines the search space for our hyperparameters we want to try), early termination policy (allows to kill poorly performing runs early), then we put this togehter as a `HyperDriveConfig` and execute it in an `HyperDriveStep`. Lastly, we have a short step to register the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.get(workspace=ws, name='workshop-env')\r\n",
    "\r\n",
    "\r\n",
    "runconfig = RunConfiguration()\r\n",
    "runconfig.environment = env\r\n",
    "\r\n",
    "script_run_config = ScriptRunConfig(source_directory=\"./\",\r\n",
    "                                    script='train.py',\r\n",
    "                                    arguments=['--data-path', training_dataset_consumption],\r\n",
    "                                    compute_target='cpu-cluster',\r\n",
    "                                    environment=env)\r\n",
    "\r\n",
    "ps = RandomParameterSampling(\r\n",
    "    {\r\n",
    "        '--c': uniform(0.1, 1.9)\r\n",
    "    }\r\n",
    ")\r\n",
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\r\n",
    "\r\n",
    "hd_config = HyperDriveConfig(run_config=script_run_config, \r\n",
    "                             hyperparameter_sampling=ps,\r\n",
    "                             policy=early_termination_policy,\r\n",
    "                             primary_metric_name='Test accuracy', \r\n",
    "                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \r\n",
    "                             max_total_runs=4,\r\n",
    "                             max_concurrent_runs=1)\r\n",
    "\r\n",
    "hd_step = HyperDriveStep(name='hyperparameter-tuning',\r\n",
    "                         hyperdrive_config=hd_config,\r\n",
    "                         inputs=[training_dataset_consumption],\r\n",
    "                         outputs=None)\r\n",
    "\r\n",
    "register_step = PythonScriptStep(name=\"register-model\",\r\n",
    "                                 source_directory=\"./\",\r\n",
    "                                 script_name='register.py',\r\n",
    "                                 arguments=['--model_name', 'best_model'],\r\n",
    "                                 runconfig=runconfig,\r\n",
    "                                 compute_target=\"cpu-cluster\",\r\n",
    "                                 allow_reuse=False)\r\n",
    "\r\n",
    "# Explicitly state that registration runs after training, as there is not direct dependency through inputs/outputs\r\n",
    "register_step.run_after(hd_step)\r\n",
    "\r\n",
    "steps = [hd_step, register_step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create our pipeline object and validate it. This will check the input and outputs are properly linked and that the pipeline graph is a non-cyclic graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=steps)\r\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can submit the pipeline against an experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pipeline_run = Experiment(ws, 'hyperparameter-pipeline').submit(pipeline)\r\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c289faa3097d4ac9289519def538503f3010d283412eb21807c4abc0fc245ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('azureml11': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}