{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Many models training pipeline\r\n",
    "\r\n",
    "In this example, we'll use ParallelRunStep to train many models in parallel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\r\n",
    "import os\r\n",
    "import azureml.core\r\n",
    "from azureml.core import Workspace, Experiment, Dataset, RunConfiguration, Environment\r\n",
    "from azureml.pipeline.core import Pipeline\r\n",
    "from azureml.pipeline.steps import PythonScriptStep, ParallelRunStep, ParallelRunConfig\r\n",
    "from azureml.data import OutputFileDatasetConfig\r\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\r\n",
    "\r\n",
    "print(\"Azure ML SDK version:\", azureml.core.VERSION)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Azure ML SDK version: 1.32.0\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we will connect to the workspace. The command `Workspace.from_config()` will either:\n",
    "* Read the local `config.json` with the workspace reference (given it is there) or\n",
    "* Use the `az` CLI to connect to the workspace and use the workspace attached to via `az ml folder attach -g <resource group> -w <workspace name>`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ws = Workspace.from_config()\r\n",
    "print(f'WS name: {ws.name}\\nRegion: {ws.location}\\nSubscription id: {ws.subscription_id}\\nResource group: {ws.resource_group}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WS name: aml-mlops-workshop\n",
      "Region: westeurope\n",
      "Subscription id: 43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a\n",
      "Resource group: aml-mlops-workshop\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation\r\n",
    "\r\n",
    "Let's upload data for our many models...well, not so many in this example, but you'll get the idea:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from azureml.core import Dataset\r\n",
    "\r\n",
    "datastore = ws.get_default_datastore()\r\n",
    "datastore.upload(src_dir='../data-many-models', target_path='many-models-training', overwrite=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading ../data-many-models\\model1\\data.csv\n",
      "Uploaded ../data-many-models\\model1\\data.csv, 1 files out of an estimated total of 3\n",
      "Uploading ../data-many-models\\model2\\data.csv\n",
      "Uploaded ../data-many-models\\model2\\data.csv, 2 files out of an estimated total of 3\n",
      "Uploading ../data-many-models\\model3\\data.csv\n",
      "Uploaded ../data-many-models\\model3\\data.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_197a1bd0fa644474bf8edb43db567cce"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the data for each model sits in its own folder, we will register the dataset with a partition definition using `partition_format`. This allows to later parallelize the training over each partition key."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ds = Dataset.File.from_files(path=[(datastore, 'many-models-training')], partition_format = '{model}/*.csv')\r\n",
    "ds.register(ws, name='many-models-training-tutorial', description='Dataset for many models tutorial', create_new_version=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'many-models-training')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"AddColumnsFromPartitionFormat\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"64da9a7f-e080-4bdd-8992-e864d7e2c0a1\",\n",
       "    \"name\": \"many-models-training-tutorial\",\n",
       "    \"version\": 2,\n",
       "    \"description\": \"Dataset for many models tutorial\",\n",
       "    \"workspace\": \"Workspace.create(name='aml-mlops-workshop', subscription_id='43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a', resource_group='aml-mlops-workshop')\"\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's reference our newly created partitioned training dataset, so that we can use it as the pipeline input. Note that we defined access mode as `direct`, this is important so that data is accessesd efficiently during parallelization."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "training_dataset = Dataset.get_by_name(ws, \"many-models-training-tutorial\")\r\n",
    "training_dataset_consumption = DatasetConsumptionConfig(\"training_dataset\", training_dataset, mode='direct')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's create a output dataset that contains our models. This gives us complete freedom where we want to store the models on the datastore. Depending on your use case (e.g., \"train & store\", or \"train & score\"), you might not need to save the generated models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "datastore = ws.get_default_datastore()\r\n",
    "\r\n",
    "# This will put the output results into a pre-defined folder on our datastore and optionally register it as a dataset (not required)\r\n",
    "models = OutputFileDatasetConfig(name='many_models',\r\n",
    "                                 destination=(datastore, 'many_models/{run-id}')).register_on_complete(name='many-models')\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can create a `ParallelRunStep` that runs our training code in parallel on one or more nodes. In this case, we use a `ParallelRunConfig` from a YAML file, that defines the parallelization of our job (source script, environement, scale, target cluster, etc.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\r\n",
    "\r\n",
    "parallel_run_config = ParallelRunConfig.load_yaml(workspace=ws, path=\"parallel_runconfig.yml\")\r\n",
    "\r\n",
    "train_step = ParallelRunStep(\r\n",
    "    name=\"train-many-models-step\",\r\n",
    "    parallel_run_config=parallel_run_config,\r\n",
    "    arguments=[ '--model_output_path', models],\r\n",
    "    inputs=[training_dataset_consumption],\r\n",
    "    side_inputs=[],\r\n",
    "    output=models,\r\n",
    "    allow_reuse=False\r\n",
    ")\r\n",
    "\r\n",
    "model_name = 'many_models_demo'\r\n",
    "runconfig = RunConfiguration()\r\n",
    "runconfig.environment = Environment.get(workspace=ws, name='workshop-env')\r\n",
    "\r\n",
    "register_step = PythonScriptStep(\r\n",
    "    name=\"register-step\",\r\n",
    "    source_directory=\"./\",\r\n",
    "    script_name=\"register.py\",\r\n",
    "    arguments=['--model_name', model_name, '--model_path', models],\r\n",
    "    inputs=[models],\r\n",
    "    compute_target='cpu-cluster',\r\n",
    "    runconfig=runconfig,\r\n",
    "    allow_reuse=False\r\n",
    ")\r\n",
    "\r\n",
    "steps = [train_step, register_step]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can create our pipeline object and validate it. This will check the input and outputs are properly linked and that the pipeline graph is a non-cyclic graph:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=steps)\r\n",
    "pipeline.validate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Step train-many-models-step is ready to be created [04408cba]\n",
      "Step register-step is ready to be created [8d392c52]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, we can submit the pipeline against an experiment:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pipeline_run = Experiment(ws, 'many-models-training-pipeline').submit(pipeline)\r\n",
    "pipeline_run.wait_for_completion()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step train-many-models-step [04408cba][418e8a6b-9c1b-4200-83bf-aef268bd0de3], (This step will run and generate new outputs)\n",
      "Created step register-step [8d392c52][6d75b191-add4-416e-9d21-82644aa07e83], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 9a0cabb7-d82d-49ea-a1f7-56255990600a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9a0cabb7-d82d-49ea-a1f7-56255990600a?wsid=/subscriptions/43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a/resourcegroups/aml-mlops-workshop/workspaces/aml-mlops-workshop&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRunId: 9a0cabb7-d82d-49ea-a1f7-56255990600a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9a0cabb7-d82d-49ea-a1f7-56255990600a?wsid=/subscriptions/43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a/resourcegroups/aml-mlops-workshop/workspaces/aml-mlops-workshop&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04?wsid=/subscriptions/43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a/resourcegroups/aml-mlops-workshop/workspaces/aml-mlops-workshop&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( train-many-models-step ) Status: NotStarted\n",
      "StepRun( train-many-models-step ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt\n",
      "========================================================================================================================\n",
      "2021-08-19T13:00:52Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=182136 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-08-19T13:00:52Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/mounts/workspaceblobstore\n",
      "2021-08-19T13:00:53Z The vmsize standard_d3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-08-19T13:00:53Z Starting output-watcher...\n",
      "2021-08-19T13:00:53Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-08-19T13:00:53Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-08-19T13:00:53Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_1e5b59c0734bdc528077f509e1d397fe\n",
      "Digest: sha256:d0c5e40cf440c619e721faa614dc94fe56cb6c41768532d169421cbe2288edc7\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_1e5b59c0734bdc528077f509e1d397fe:latest\n",
      "2021-08-19T13:00:53Z The vmsize standard_d3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-08-19T13:00:53Z Check if container 0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04_DataSidecar already exist exited with 0, \n",
      "\n",
      "ca6fdb4ff2c384f9b08298d8f12f89795e0a0c0f1bf855695ee0c19bae93350e\n",
      "2021-08-19T13:00:54Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-08-19T13:00:54Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-1fa1237a6a05d6659621d1e456149171-327c4c7ad21be409-01 -sshRequired=false] \n",
      "2021/08/19 13:00:54 Starting App Insight Logger for task:  containerSetup\n",
      "2021/08/19 13:00:54 Version: 3.0.01678.0001 Branch: 2021-08-06 Commit: fee6fc3\n",
      "2021/08/19 13:00:54 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/08/19 13:00:54 Starting infiniband setup\n",
      "2021/08/19 13:00:54 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/19 13:00:54 Returning Python Version as 3.7\n",
      "2021-08-19T13:00:54Z VMSize: standard_d3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/19 13:00:54 VMSize: standard_d3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/19 13:00:54 VMSize: standard_d3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/08/19 13:00:54 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021-08-19T13:00:54Z Not setting up Infiniband in Container\n",
      "2021/08/19 13:00:54 Not setting up Infiniband in Container\n",
      "2021/08/19 13:00:54 Not setting up Infiniband in Container\n",
      "2021/08/19 13:00:54 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/08/19 13:00:54 Returning Python Version as 3.7\n",
      "2021/08/19 13:00:54 sshd inside container not required for job, skipping setup.\n",
      "2021/08/19 13:00:54 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
      "2021/08/19 13:00:54 App Insight Client has already been closed\n",
      "2021/08/19 13:00:54 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-08-19T13:00:54Z Starting docker container succeeded.\n",
      "2021-08-19T13:00:54Z The vmsize standard_d3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/08/19 13:01:20 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/08/19 13:01:20 Version: 3.0.01678.0001 Branch: 2021-08-06 Commit: fee6fc3\n",
      "2021/08/19 13:01:20 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/08/19 13:01:20 Send process info logs to master server succeeded\n",
      "2021/08/19 13:01:20 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "2021/08/19 13:01:20 Send process info logs to master server succeeded\n",
      "[2021-08-19T13:01:20.419205] Entering context manager injector.\n",
      "[2021-08-19T13:01:20.864648] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.32.0', '--scoring_module_name', 'train_parallel.py', '--mini_batch_size', '10', '--error_threshold', '0', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '180', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'train_results.txt', '--output', 'DatasetOutputConfig:many_models', '--process_count_per_node', '2', '--partition_keys', '[\"model\"]', '--model_output_path', 'DatasetOutputConfig:many_models', '--input_fds_0', 'training_dataset'])\n",
      "Script type = None\n",
      "[2021-08-19T13:01:20.868670] Entering Run History Context Manager.\n",
      "[2021-08-19T13:01:22.013598] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/wd/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04\n",
      "[2021-08-19T13:01:22.013632] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.32.0', '--scoring_module_name', 'train_parallel.py', '--mini_batch_size', '10', '--error_threshold', '0', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '180', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'train_results.txt', '--output', '$many_models', '--process_count_per_node', '2', '--partition_keys', '[\"model\"]', '--model_output_path', '$many_models', '--input_fds_0', 'training_dataset']\n",
      "[2021-08-19T13:01:22.013650] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.32.0', '--scoring_module_name', 'train_parallel.py', '--mini_batch_size', '10', '--error_threshold', '0', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '180', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'train_results.txt', '--output', '/tmp/57be64e7-50bf-44e2-bc72-0ccbd4fec7f6', '--process_count_per_node', '2', '--partition_keys', '[\"model\"]', '--model_output_path', '/tmp/57be64e7-50bf-44e2-bc72-0ccbd4fec7f6', '--input_fds_0', 'training_dataset']\n",
      "\n",
      "2021/08/19 13:01:25 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt\n",
      "===============================================================================================================\n",
      "[2021-08-19T13:02:30.495408] Entering job release\n",
      "[2021-08-19T13:02:31.363037] Starting job release\n",
      "[2021-08-19T13:02:31.364026] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 265\n",
      "[2021-08-19T13:02:31.364550] job release stage : upload_datastore starting...\n",
      "[2021-08-19T13:02:31.364842] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-08-19T13:02:31.365253] job release stage : copy_batchai_cached_logs starting...[2021-08-19T13:02:31.367450] job release stage : execute_job_release starting...\n",
      "[2021-08-19T13:02:31.367615] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "[2021-08-19T13:02:31.379876] Entering context manager injector.\n",
      "[2021-08-19T13:02:31.386613] job release stage : upload_datastore completed...\n",
      "[2021-08-19T13:02:31.484050] job release stage : send_run_telemetry starting...\n",
      "[2021-08-19T13:02:31.529853] get vm size and vm region successfully.\n",
      "[2021-08-19T13:02:31.537320] get compute meta data successfully.\n",
      "[2021-08-19T13:02:31.619109] job release stage : execute_job_release completed...\n",
      "[2021-08-19T13:02:31.695437] post artifact meta request successfully.\n",
      "[2021-08-19T13:02:31.725458] upload compute record artifact successfully.\n",
      "[2021-08-19T13:02:31.725552] job release stage : send_run_telemetry completed...\n",
      "[2021-08-19T13:02:31.725955] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-08-19T13:02:31.726038] Running Sidecar release cmd...\n",
      "[2021-08-19T13:02:31.737700] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/wd/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/wd/many_models_workspaceblobstore.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml-mlops-workshop/azureml/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/wd/many_models_workspaceblobstore.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-08-19T13:02:31.772920] Removing absolute paths from host...\n",
      "[2021-08-19T13:02:31.773154] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-08-19T13:02:32.471817] Ran Sidecar release cmd.\n",
      "[2021-08-19T13:02:32.471972] Job release is complete\n",
      "\n",
      "StepRun(train-many-models-step) Execution Summary\n",
      "==================================================\n",
      "StepRun( train-many-models-step ) Status: Finished\n",
      "{'runId': '0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2021-08-19T13:00:52.178964Z', 'endTimeUtc': '2021-08-19T13:03:36.350461Z', 'properties': {'ContentSnapshotId': '5e22c4f1-8c1f-488b-9292-95babfc433c5', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '418e8a6b-9c1b-4200-83bf-aef268bd0de3', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '04408cba', 'azureml.pipelinerunid': '9a0cabb7-d82d-49ea-a1f7-56255990600a', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': '64da9a7f-e080-4bdd-8992-e864d7e2c0a1'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_dataset', 'mechanism': 'Direct'}}, {'dataset': {'id': '5940f386-6947-4d20-b191-c0fba2c81f59'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [{'identifier': {'savedId': '5940f386-6947-4d20-b191-c0fba2c81f59', 'registeredId': '233c51a3-1573-4376-8778-e74401def22e', 'registeredVersion': '2'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'many_models'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'many_models/0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"5940f386-6947-4d20-b191-c0fba2c81f59\",\n",
      "    \"name\": \"many-models\",\n",
      "    \"version\": 2,\n",
      "    \"workspace\": \"Workspace.create(name='aml-mlops-workshop', subscription_id='43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a', resource_group='aml-mlops-workshop')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.32.0', '--scoring_module_name', 'train_parallel.py', '--mini_batch_size', '10', '--error_threshold', '0', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '180', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'train_results.txt', '--output', 'DatasetOutputConfig:many_models', '--process_count_per_node', '2', '--partition_keys', '[\"model\"]', '--model_output_path', 'DatasetOutputConfig:many_models', '--input_fds_0', 'training_dataset'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster', 'dataReferences': {}, 'data': {'training_dataset': {'dataLocation': {'dataset': {'id': '64da9a7f-e080-4bdd-8992-e864d7e2c0a1', 'name': None, 'version': '2'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'training_dataset', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {'many_models': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'many_models/{run-id}'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': '/tmp/57be64e7-50bf-44e2-bc72-0ccbd4fec7f6/', 'registrationOptions': {'name': 'many-models', 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'workshop-env', 'version': 'Autosave_2021-08-19T11:44:55Z_532ac048', 'python': {'interpreterPath': None, 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge', 'defaults'], 'dependencies': ['python=3.8.5', {'pip': ['azureml-defaults>=1.31.0', 'azureml-sdk>=1.31.0', 'scikit-learn==0.24.1', 'pandas==1.2.1', 'joblib==1.0.0']}], 'name': 'azureml_2ca7d4813b3969dfb804fc3f40a6ab21'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': 'westus2', 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'jarLibraries': [], 'eggLibraries': [], 'whlLibraries': [], 'pypiLibraries': [], 'rCranLibraries': [], 'mavenLibraries': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/azureml-logs/55_azureml-execution-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt?sv=2019-07-07&sr=b&sig=tufCKgPHh8YGnWnooFFkCMWujxA6GuCBhcJrbOInzfY%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'azureml-logs/65_job_prep-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/azureml-logs/65_job_prep-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt?sv=2019-07-07&sr=b&sig=lSOdoHK54WO1CcNcLnJrKbWewrsmvw3yv9gamCn0z28%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=lxTWE1YoHuWMzd0IR8eUlizGL%2BetUuIT49Uc2dUuykU%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'azureml-logs/75_job_post-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/azureml-logs/75_job_post-tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d.txt?sv=2019-07-07&sr=b&sig=mq2FpsT86upjrEnRZ1nqUYbLwPwlt07iRCX5c00nQdM%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'azureml-logs/process_info.json': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=dQ7vN3gkeMJmTcVLIZ3gQ57qIiINZ1NZ9AraS2dc1oY%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'azureml-logs/process_status.json': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=gCjy%2Fk5dtOD5HcXq8ih5OqMQTTMZ2XDcJBR4Z6dY2qk%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/75_azureml.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/75_azureml.log?sv=2019-07-07&sr=b&sig=%2FrukVhOTNBgi9Luh2rc6K26%2FZozzIOYE9pqlcs45HFE%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=LGECKtofKNuyRdPz3U7EW1nqoOVJm2KCdsyb1TiagT4%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=%2BvkzU1ghbUu14OcdJsQVUMf5SpSK29BXm5l7ue3SyXY%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=c50T0PfVCSFuacL7Y63BemC4Qlfxuh9Wp96o56bwPo4%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=muzpQa9NyB9VH%2FiNixakRi6ujObB%2B8AuD5wpHzNGd7o%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=ww3Nhe0%2FKDh3A0uvVOQ%2FAIwZN3%2BFkxjf0sWfrFFWOA4%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/sidecar/tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d/all.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/sidecar/tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d/all.log?sv=2019-07-07&sr=b&sig=pZCVqU8RIHXjdMSeHqo8gO86q1YzHQa59tN%2Fs7ugfIE%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/sidecar/tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d/task.enter_contexts.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/sidecar/tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d/task.enter_contexts.log?sv=2019-07-07&sr=b&sig=sXBkhCAVXNe3MON4fYRyY5zgqzyk%2BrcAVCZp3UkQB1Y%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/sidecar/tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d/task.exit_contexts.log': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/sidecar/tvmps_da6bcf1bb45e10400a6492c7ce5a885d40d5542807bdd9f099718912956f7d80_d/task.exit_contexts.log?sv=2019-07-07&sr=b&sig=nqKZAFQXHW%2BKiYQzD8lbZ5yGrynC8o%2FooVuhOFO5mGk%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=QLoXxCNY%2F0xpmuWaw0atYti6IbdFyZBvyFd6BNM0jl4%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlmlopsworksh7988334843.blob.core.windows.net/azureml/ExperimentRun/dcid.0e37ecbd-a4ea-4a10-b3dc-fee33bee0d04/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=kWY%2F04GNuiQWb2YNBm5ghN%2FubwH8XR09yRGTfT%2BVGGw%3D&st=2021-08-19T12%3A52%3A35Z&se=2021-08-19T21%3A02%3A35Z&sp=r'}, 'submittedBy': 'Clemens Siebler (HE/HIM)'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: d73afc6f-c763-45f9-88bf-b1928c9f611a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/d73afc6f-c763-45f9-88bf-b1928c9f611a?wsid=/subscriptions/43ab27bb-ee6c-4f68-b9cf-a26c4c454a4a/resourcegroups/aml-mlops-workshop/workspaces/aml-mlops-workshop&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( register-step ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/08/19 13:03:48 Downloading source code...\n",
      "2021/08/19 13:03:49 Finished downloading source code\n",
      "2021/08/19 13:03:50 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/08/19 13:03:51 Successfully set up Docker network: acb_default_network\n",
      "2021/08/19 13:03:51 Setting up Docker configuration...\n",
      "2021/08/19 13:03:52 Successfully set up Docker configuration\n",
      "2021/08/19 13:03:52 Logging in to registry: amlsharedclemens.azurecr.io\n",
      "2021/08/19 13:03:53 Successfully logged into amlsharedclemens.azurecr.io\n",
      "2021/08/19 13:03:53 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/08/19 13:03:53 Scanning for dependencies...\n",
      "2021/08/19 13:03:54 Successfully scanned dependencies\n",
      "2021/08/19 13:03:54 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "4bbfd2c87b75: Pulling fs layer\n",
      "d2e110be24e1: Pulling fs layer\n",
      "889a7173dcfe: Pulling fs layer\n",
      "7a7a145ebf57: Pulling fs layer\n",
      "1ae81884420d: Pulling fs layer\n",
      "fcdf07e25452: Pulling fs layer\n",
      "95262654cd7f: Pulling fs layer\n",
      "520cb0fab4f5: Pulling fs layer\n",
      "00c1c086d027: Pulling fs layer\n",
      "282c4a3b6fb6: Pulling fs layer\n",
      "f4201c7ca826: Pulling fs layer\n",
      "7a7a145ebf57: Waiting\n",
      "1ae81884420d: Waiting\n",
      "fcdf07e25452: Waiting\n",
      "95262654cd7f: Waiting\n",
      "520cb0fab4f5: Waiting\n",
      "00c1c086d027: Waiting\n",
      "282c4a3b6fb6: Waiting\n",
      "f4201c7ca826: Waiting\n",
      "889a7173dcfe: Verifying Checksum\n",
      "889a7173dcfe: Download complete\n",
      "d2e110be24e1: Verifying Checksum\n",
      "d2e110be24e1: Download complete\n",
      "4bbfd2c87b75: Verifying Checksum\n",
      "4bbfd2c87b75: Download complete\n",
      "1ae81884420d: Verifying Checksum\n",
      "1ae81884420d: Download complete\n",
      "fcdf07e25452: Verifying Checksum\n",
      "fcdf07e25452: Download complete\n",
      "520cb0fab4f5: Verifying Checksum\n",
      "520cb0fab4f5: Download complete\n",
      "00c1c086d027: Verifying Checksum\n",
      "00c1c086d027: Download complete\n",
      "282c4a3b6fb6: Verifying Checksum\n",
      "282c4a3b6fb6: Download complete\n",
      "f4201c7ca826: Verifying Checksum\n",
      "f4201c7ca826: Download complete\n",
      "7a7a145ebf57: Verifying Checksum\n",
      "7a7a145ebf57: Download complete\n",
      "4bbfd2c87b75: Pull complete\n",
      "d2e110be24e1: Pull complete\n",
      "95262654cd7f: Verifying Checksum\n",
      "95262654cd7f: Download complete\n",
      "889a7173dcfe: Pull complete\n",
      "7a7a145ebf57: Pull complete\n",
      "1ae81884420d: Pull complete\n",
      "fcdf07e25452: Pull complete\n",
      "95262654cd7f: Pull complete\n",
      "520cb0fab4f5: Pull complete\n",
      "00c1c086d027: Pull complete\n",
      "282c4a3b6fb6: Pull complete\n",
      "f4201c7ca826: Pull complete\n",
      "Digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
      " ---> 6ba46986c29e\n",
      "Step 2/18 : USER root\n",
      " ---> Running in 39189b98e7da\n",
      "Removing intermediate container 39189b98e7da\n",
      " ---> a3b6ad3f2b6f\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 291a143818ab\n",
      "Removing intermediate container 291a143818ab\n",
      " ---> 8170db1198f3\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in f16507540f41\n",
      "Removing intermediate container f16507540f41\n",
      " ---> 31c94e11ea62\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 13047bdb4fa4\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 933e6bf9f06e\n",
      "Removing intermediate container 933e6bf9f06e\n",
      " ---> 795a51fac90a\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> ab99d22d3bf0\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_da3e97fcb51801118b8e80207f3e01ad -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 5812ef2e464b\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Last but not least, we can nnow download the resulting models dataset. For easy of use, we'll just download the models and the summary here to a folder named `temp`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Dataset.get_by_name(ws, \"many-models\").download(target_path=\"temp/\", overwrite=True)\r\n",
    "with open('temp/train_results.txt','r') as f:\r\n",
    "    print(f.read())"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c289faa3097d4ac9289519def538503f3010d283412eb21807c4abc0fc245ea"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('azureml11': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}